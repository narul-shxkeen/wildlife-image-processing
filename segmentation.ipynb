{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff649bd",
   "metadata": {},
   "source": [
    "# Create SAM â†’ YOLOv12 Dataset\n",
    "\n",
    "This notebook samples images from the `dataset/` folder, runs the Segment Anything Model (SAM v2) to generate masks, extracts bounding boxes from masks, maps species labels from `image_categories_cleaned.json` to integer class IDs, and writes a YOLOv12-style dataset into an `output/` folder.\n",
    "\n",
    "Usage notes:\n",
    "- You can edit the parameters cell below to change sampling size, area threshold, SAM checkpoint, and output directory.\n",
    "- Make sure SAM and required libraries are installed in the notebook kernel environment (see `requirements-sam-yolo.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d8b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded helper functions\n"
     ]
    }
   ],
   "source": [
    "# Imports and helper functions\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# SAM import (may raise if not installed)\n",
    "try:\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "except Exception as e:\n",
    "    print('Warning: segment_anything import failed. Install the package to run segmentation cells.')\n",
    "    raise\n",
    "\n",
    "\n",
    "def xyxy_to_yolo(box, img_w, img_h):\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    x_center = (x_min + x_max) / 2.0\n",
    "    y_center = (y_min + y_max) / 2.0\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    return [x_center / img_w, y_center / img_h, width / img_w, height / img_h]\n",
    "\n",
    "print('Loaded helper functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6741fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set:\n",
      "DATASET_DIR=dataset\n",
      "LABELS_JSON=image_categories_cleaned.json\n",
      "OUTPUT_DIR=output_sam_yolo_notebook\n",
      "NUM_SAMPLES=200, AREA_THRESHOLD=0.01, SAM_MODEL_TYPE=vit_b\n",
      "SAM_CHECKPOINT=sam_vit_b_01ec64.pth (DOWNLOAD_CHECKPOINT=True)\n"
     ]
    }
   ],
   "source": [
    "# Parameters (edit these as needed)\n",
    "DATASET_DIR = Path('dataset')\n",
    "LABELS_JSON = Path('image_categories_cleaned.json')\n",
    "# Default checkpoint filename (will auto-download if missing when DOWNLOAD_CHECKPOINT=True)\n",
    "SAM_CHECKPOINT = Path('./sam_vit_b_01ec64.pth')  # <-- will be downloaded automatically by the notebook if not present\n",
    "OUTPUT_DIR = Path('output_sam_yolo_notebook')\n",
    "NUM_SAMPLES = 200\n",
    "SEED = 42\n",
    "AREA_THRESHOLD = 0.01  # fraction of image area\n",
    "SAM_MODEL_TYPE = 'vit_b'\n",
    "\n",
    "# Auto-download behavior (set to False if you want to manually provide checkpoint)\n",
    "DOWNLOAD_CHECKPOINT = True\n",
    "# Official FB public URL for the vit_b checkpoint (used if DOWNLOAD_CHECKPOINT=True)\n",
    "SAM_VIT_B_URL = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth'\n",
    "\n",
    "print('Parameters set:')\n",
    "print(f'DATASET_DIR={DATASET_DIR}')\n",
    "print(f'LABELS_JSON={LABELS_JSON}')\n",
    "print(f'OUTPUT_DIR={OUTPUT_DIR}')\n",
    "print(f'NUM_SAMPLES={NUM_SAMPLES}, AREA_THRESHOLD={AREA_THRESHOLD}, SAM_MODEL_TYPE={SAM_MODEL_TYPE}')\n",
    "print(f'SAM_CHECKPOINT={SAM_CHECKPOINT} (DOWNLOAD_CHECKPOINT={DOWNLOAD_CHECKPOINT})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303000ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM checkpoint sam_vit_b_01ec64.pth not found locally. Attempting to download from https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth ...\n",
      "Downloaded SAM checkpoint to: sam_vit_b_01ec64.pth\n",
      "Sampled 200 images\n",
      "Found 9 species\n",
      "Loading SAM model...\n",
      "Downloaded SAM checkpoint to: sam_vit_b_01ec64.pth\n",
      "Sampled 200 images\n",
      "Found 9 species\n",
      "Loading SAM model...\n",
      "Processed 10/200\n",
      "Processed 10/200\n",
      "Processed 20/200\n",
      "Processed 20/200\n",
      "Processed 30/200\n",
      "Processed 30/200\n",
      "Processed 40/200\n",
      "Processed 40/200\n",
      "Processed 50/200\n",
      "Processed 50/200\n",
      "Processed 60/200\n",
      "Processed 60/200\n",
      "Processed 70/200\n",
      "Processed 70/200\n"
     ]
    }
   ],
   "source": [
    "# Main processing cell: sample images, run SAM, create YOLO labels\n",
    "\n",
    "# Auto-download SAM checkpoint if requested\n",
    "if DOWNLOAD_CHECKPOINT and not SAM_CHECKPOINT.exists():\n",
    "    print(f\"SAM checkpoint {SAM_CHECKPOINT} not found locally. Attempting to download from {SAM_VIT_B_URL} ...\")\n",
    "    try:\n",
    "        import urllib.request\n",
    "        SAM_CHECKPOINT.parent.mkdir(parents=True, exist_ok=True)\n",
    "        urllib.request.urlretrieve(SAM_VIT_B_URL, str(SAM_CHECKPOINT))\n",
    "        print(f\"Downloaded SAM checkpoint to: {SAM_CHECKPOINT}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to download SAM checkpoint automatically: {e}. Please download manually and set SAM_CHECKPOINT.\")\n",
    "\n",
    "# Validate input paths early and provide clear error messages\n",
    "if not DATASET_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Dataset directory not found: {DATASET_DIR}. Make sure the path is correct and the folder exists.\")\n",
    "if not LABELS_JSON.exists():\n",
    "    raise FileNotFoundError(f\"Labels JSON not found: {LABELS_JSON}. Make sure `image_categories_cleaned.json` exists in the notebook folder or update LABELS_JSON.\")\n",
    "if not SAM_CHECKPOINT.exists():\n",
    "    raise FileNotFoundError(f\"SAM checkpoint not found: {SAM_CHECKPOINT}. Set `SAM_CHECKPOINT` to a valid .pth checkpoint path before running this cell.\")\n",
    "\n",
    "output_images_dir = OUTPUT_DIR / 'images'\n",
    "output_labels_dir = OUTPUT_DIR / 'labels'\n",
    "output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load labels\n",
    "with open(LABELS_JSON, 'r', encoding='utf-8') as f:\n",
    "    image_categories = json.load(f)\n",
    "\n",
    "# Gather available images\n",
    "all_images = [p.name for p in DATASET_DIR.iterdir() if p.is_file() and p.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "available_images = [img for img in all_images if img in image_categories]\n",
    "\n",
    "if len(available_images) == 0:\n",
    "    raise RuntimeError('No images available that match labels. Please check dataset directory and labels JSON.')\n",
    "\n",
    "NUM_SAMPLES_ACTUAL = min(NUM_SAMPLES, len(available_images))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "sampled = random.sample(available_images, NUM_SAMPLES_ACTUAL)\n",
    "print(f'Sampled {NUM_SAMPLES_ACTUAL} images')\n",
    "\n",
    "# Map species to ids\n",
    "species_set = set()\n",
    "for img in sampled:\n",
    "    cats = image_categories.get(img)\n",
    "    if not cats:\n",
    "        continue\n",
    "    if isinstance(cats, list) and len(cats) > 0:\n",
    "        species_set.add(cats[0])\n",
    "    elif isinstance(cats, str):\n",
    "        species_set.add(cats)\n",
    "species_list = sorted(list(species_set))\n",
    "species_to_id = {sp: i for i, sp in enumerate(species_list)}\n",
    "with open(OUTPUT_DIR / 'classes.txt', 'w', encoding='utf-8') as f:\n",
    "    for sp in species_list:\n",
    "        f.write(sp + '\\n')\n",
    "\n",
    "print(f'Found {len(species_list)} species')\n",
    "\n",
    "# Load SAM (guard against typical errors)\n",
    "print('Loading SAM model...')\n",
    "try:\n",
    "    sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=str(SAM_CHECKPOINT))\n",
    "except KeyError:\n",
    "    raise KeyError(f\"SAM model type '{SAM_MODEL_TYPE}' not found in sam_model_registry. Available keys: {list(sam_model_registry.keys())}\")\n",
    "except Exception as e:\n",
    "    # Provide a helpful message when checkpoint load fails\n",
    "    raise RuntimeError(f\"Failed to initialize SAM model. Error: {e}. Check that the checkpoint file is valid and compatible with the selected SAM model type.\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "sam.to(device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "processed = 0\n",
    "for img_name in sampled:\n",
    "    src_path = DATASET_DIR / img_name\n",
    "    dst_img_path = output_images_dir / img_name\n",
    "    img_bgr = cv2.imread(str(src_path))\n",
    "    if img_bgr is None:\n",
    "        print(f'Warning: failed to read {src_path}, skipping')\n",
    "        continue\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = img_rgb.shape\n",
    "\n",
    "    masks = mask_generator.generate(img_rgb)\n",
    "    keep_bboxes = []\n",
    "    \n",
    "    keep_bboxes = []\n",
    "mask_areas = []\n",
    "\n",
    "for m in masks:\n",
    "    mask = m['segmentation']\n",
    "    area_fraction = mask.sum() / (h * w)\n",
    "    if area_fraction < AREA_THRESHOLD:\n",
    "        continue\n",
    "    ys, xs = np.where(mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        continue\n",
    "    x_min, x_max, y_min, y_max = xs.min(), xs.max(), ys.min(), ys.max()\n",
    "    area = (x_max - x_min) * (y_max - y_min)\n",
    "    keep_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "    mask_areas.append(area)\n",
    "\n",
    "# Keep only the largest mask\n",
    "if len(keep_bboxes) > 0:\n",
    "    largest_idx = np.argmax(mask_areas)\n",
    "    keep_bboxes = [keep_bboxes[largest_idx]]\n",
    "\n",
    "    \n",
    "    # for m in masks:\n",
    "    #     mask = m['segmentation']\n",
    "    #     area_fraction = mask.sum() / (h * w)\n",
    "    #     if area_fraction < AREA_THRESHOLD:\n",
    "    #         continue\n",
    "    #     ys, xs = np.where(mask)\n",
    "    #     if len(xs) == 0 or len(ys) == 0:\n",
    "    #         continue\n",
    "    #     x_min = int(xs.min())\n",
    "    #     x_max = int(xs.max())\n",
    "    #     y_min = int(ys.min())\n",
    "    #     y_max = int(ys.max())\n",
    "    #     keep_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    cats = image_categories.get(img_name)\n",
    "    if not cats:\n",
    "        species_label = None\n",
    "    else:\n",
    "        if isinstance(cats, list):\n",
    "            species_label = cats[0]\n",
    "        else:\n",
    "            species_label = cats\n",
    "\n",
    "    shutil.copy2(src_path, dst_img_path)\n",
    "\n",
    "    label_lines = []\n",
    "    if species_label is not None and species_label in species_to_id and len(keep_bboxes) > 0:\n",
    "        class_id = species_to_id[species_label]\n",
    "        for box in keep_bboxes:\n",
    "            yolo_box = xyxy_to_yolo(box, w, h)\n",
    "            label_lines.append(f\"{class_id} {' '.join([f'{v:.6f}' for v in yolo_box])}\")\n",
    "\n",
    "    label_file = output_labels_dir / (img_name.rsplit('.', 1)[0] + '.txt')\n",
    "    with open(label_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(label_lines))\n",
    "\n",
    "    processed += 1\n",
    "    if processed % 10 == 0:\n",
    "        print(f'Processed {processed}/{NUM_SAMPLES_ACTUAL}')\n",
    "\n",
    "print(f'Done. Processed {processed} images. Output at: {OUTPUT_DIR}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildlifeImageClassification (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
